{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel('test_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14745 entries, 0 to 14744\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   ID               14745 non-null  int64         \n",
      " 1   Frequency        14745 non-null  object        \n",
      " 2   InstlmentMode    14745 non-null  object        \n",
      " 3   LoanStatus       14745 non-null  object        \n",
      " 4   PaymentMode      14745 non-null  object        \n",
      " 5   BranchID         14745 non-null  int64         \n",
      " 6   Area             14199 non-null  object        \n",
      " 7   Tenure           14745 non-null  int64         \n",
      " 8   AssetCost        14745 non-null  int64         \n",
      " 9   AmountFinance    14745 non-null  float64       \n",
      " 10  DisbursalAmount  14745 non-null  float64       \n",
      " 11  EMI              14745 non-null  float64       \n",
      " 12  DisbursalDate    14745 non-null  datetime64[ns]\n",
      " 13  MaturityDAte     14745 non-null  datetime64[ns]\n",
      " 14  AuthDate         14745 non-null  datetime64[ns]\n",
      " 15  AssetID          14745 non-null  int64         \n",
      " 16  ManufacturerID   14743 non-null  float64       \n",
      " 17  SupplierID       14745 non-null  int64         \n",
      " 18  LTV              14745 non-null  float64       \n",
      " 19  SEX              14740 non-null  object        \n",
      " 20  AGE              14738 non-null  float64       \n",
      " 21  MonthlyIncome    14731 non-null  float64       \n",
      " 22  City             14745 non-null  object        \n",
      " 23  State            14745 non-null  object        \n",
      " 24  ZiPCODE          14744 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(8), int64(6), object(8)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value for AGE: 18.0\n",
      "Maximum value for AGE: 85.0\n"
     ]
    }
   ],
   "source": [
    "print('Minimum value for AGE:', data_df['AGE'].min())\n",
    "print('Maximum value for AGE:', data_df['AGE'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_Bins = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy='quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of unique bins: 8\n",
      "Unique values assigned to each bin: [6 3 5 2 4 1 0 7]\n"
     ]
    }
   ],
   "source": [
    "data_df['Age_Bins'] =Age_Bins.fit_transform(data_df['AGE'].values.reshape(-1,1)).astype(int)\n",
    "print('Total count of unique bins:', data_df['Age_Bins'].nunique())\n",
    "print('Unique values assigned to each bin:', data_df['Age_Bins'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48., 45., 47., 44., 46.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['Age_Bins'] == 5]['AGE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll consider the feature 'Area' to perform the frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Area'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GUNA', 'CUTTACK', 'BURDWAN', 'CHANDIGARH', 'JAIPUR', 'JALANDHAR',\n",
       "       'KANPUR', 'KARNAL', 'DEHRADUN', 'UDAIPUR', 'NELLORE',\n",
       "       'AHMEDABAD AMBAVADI', 'BARODA', 'PARBHANI', 'MIRYALGUDA', 'INDORE',\n",
       "       'LUDHIANA FEROZ GANDHI MARKET', 'KOTA', 'AHMEDABAD CG ROAD',\n",
       "       'BHUBANESHWAR', 'RAJKOT', 'BHOPAL', 'VIDISHA', 'JABALPUR',\n",
       "       'RAIPUR', 'BILASPUR', 'DURGAPUR', 'LUDHIANA   RANI JHANSI ROAD',\n",
       "       'LUCKNOW', 'BANGALORE LALBAGH', 'GULBARGA', 'HUBLI', 'MANGALORE',\n",
       "       'HYDERABAD BEGUMPET', 'KARIMNAGAR', 'MYSORE', 'NIZAMABAD',\n",
       "       'SINDHANUR', 'VIJAYAWADA', 'VISHAKHAPATNAM', 'AMRAVATI',\n",
       "       'GANDHIDHAM', 'LATUR', 'SOLAPUR', 'NAGPUR', 'NASHIK',\n",
       "       'PUNE APTE ROAD', 'AHMEDNAGAR', 'TUMKUR', 'TADEPALLIGUDEM',\n",
       "       'RAJAHMUNDRY', 'AURANGABAD', 'NEW DELHI BARAKHAMBHA ROAD',\n",
       "       'MANDSAUR', 'SILIGURI', 'AKOLA', 'SIRSA', 'HOSHANGABAD',\n",
       "       'KOLHAPUR', 'PATNA', 'SIWAN', 'BIKANER', 'UJJAIN', 'REWARI',\n",
       "       'HANUMANGARH', 'KANKER', 'RATLAM', 'GHAZIABAD', 'FAIZABAD',\n",
       "       'BHANDARA', 'KHAMGAON', 'YAMUNANAGAR', 'JODHPUR', 'PALWAL',\n",
       "       'GANGANAGAR', 'PANIPAT', 'KOLKATA WOOD STREET', 'BELAPUR', 'CHURU',\n",
       "       'JALORE'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_enc = data_df.groupby('Area').size()/len(data_df)\n",
    "data_df['freq_Area'] = data_df['Area'].map(freq_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique values after freq encoding: 61\n"
     ]
    }
   ],
   "source": [
    "print('Total number of unique values after freq encoding:', data_df['freq_Area'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.10125511e-02, 8.60245381e-03, 7.68579890e-03, 1.55126216e-02,\n",
       "       1.36087999e-02, 1.51600621e-02, 9.44859681e-03, 1.71343957e-02,\n",
       "       4.68904245e-02, 3.83584826e-02, 2.82047666e-02, 5.07685799e-02,\n",
       "       1.01537160e-02, 1.38908476e-02, 4.30122691e-02, 1.16274150e-01,\n",
       "       1.09293471e-02, 1.31927796e-01, 7.05119165e-04, 1.77690030e-02,\n",
       "       1.14934424e-02, 7.54477507e-03, 2.39740516e-02, 9.66013256e-03,\n",
       "       8.03835848e-03, 2.82047666e-03, 1.19870258e-03, 3.94866732e-03,\n",
       "       1.46664786e-02, 5.64095332e-04, 2.15061345e-02, 1.25511211e-02,\n",
       "       8.24989423e-03, 2.82047666e-04, 2.17176703e-02, 1.33972641e-03,\n",
       "       9.37808490e-03, 1.97433366e-03, 5.78197715e-03, 1.76279791e-03,\n",
       "       1.24806092e-02, 8.67296573e-03, 7.19221548e-03, 3.17303624e-03,\n",
       "       2.11535750e-04, 3.52559583e-04, 2.60894091e-03, 3.87815541e-03,\n",
       "       1.90382175e-03, 4.49866027e-02, 9.16654915e-03, 3.59610774e-02,\n",
       "       8.17938232e-03, 5.71146524e-03, 2.32689324e-03, 7.05119165e-05,\n",
       "       1.69228600e-03, 6.34607249e-04, 1.41023833e-04, 1.62177408e-03,\n",
       "       8.46142998e-04])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['freq_Area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the LoanStatus: 2\n",
      "Number of unique values in the Frequency: 3\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique values in the LoanStatus:', data_df['LoanStatus'].nunique())\n",
    "print('Number of unique values in the Frequency:', data_df['Frequency'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as catenc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "data_df['LoanStatus'] = labelencoder.fit_transform(data_df['LoanStatus'])\n",
    "\n",
    "targetenc = catenc.TargetEncoder(smoothing=1, min_samples_leaf=1)\n",
    "data_df['freq_loan'] = targetenc.fit_transform(data_df['Frequency'], data_df['LoanStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92183288, 0.70552561, 0.73538961])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['freq_loan'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Frequency</th>\n",
       "      <th>Half Yearly</th>\n",
       "      <th>Monthly</th>\n",
       "      <th>Quatrly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanStatus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2771</td>\n",
       "      <td>174</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7701</td>\n",
       "      <td>2052</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Frequency   Half Yearly  Monthly  Quatrly\n",
       "LoanStatus                               \n",
       "0                  2771      174      437\n",
       "1                  7701     2052     1047"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data_df['LoanStatus'], data_df['Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loanstat0 = data_df[data_df['LoanStatus'] == 0].shape[0]\n",
    "Loanstat1 = data_df[data_df['LoanStatus'] == 1].shape[0]\n",
    "\n",
    "Loan_prop0 = Loanstat0/data_df.shape[0]\n",
    "Loan_prop1 = Loanstat1/data_df.shape[0]\n",
    "\n",
    "HY_total = data_df[(data_df['Frequency'] == 'Half Yearly')].shape[0]\n",
    "HY_Freq0 = data_df[(data_df['LoanStatus'] == 0) & (data_df['Frequency'] == 'Half Yearly') ].shape[0]/HY_total\n",
    "HY_Freq1 = data_df[(data_df['LoanStatus'] == 1) & (data_df['Frequency'] == 'Half Yearly') ].shape[0]/HY_total\n",
    "\n",
    "Mon_total = data_df[data_df['Frequency'] == 'Monthly'].shape[0]\n",
    "Mon_Freq0 = data_df[(data_df['LoanStatus'] == 0) & (data_df['Frequency'] == 'Monthly') ].shape[0]/Mon_total\n",
    "Mon_Freq1 = data_df[(data_df['LoanStatus'] == 1) & (data_df['Frequency'] == 'Monthly') ].shape[0]/Mon_total\n",
    "\n",
    "Qua_total = data_df[data_df['Frequency'] == 'Quatrly'].shape[0]\n",
    "Qua_Freq0 = data_df[(data_df['LoanStatus'] == 0) & (data_df['Frequency'] == 'Quatrly') ].shape[0]/Qua_total\n",
    "Qua_Freq1 = data_df[(data_df['LoanStatus'] == 1) & (data_df['Frequency'] == 'Quatrly') ].shape[0]/Qua_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan proportion for 0: 0.23847130164997885\n",
      "Loan proportion for 1: 0.7615286983500211\n",
      "\n",
      "Half_Yearly proprotion for 0: 0.26461038961038963\n",
      "Half_Yearly proprotion for 1: 0.7353896103896104\n",
      "\n",
      "Monthly proprotion for 0: 0.07816711590296496\n",
      "Monthly proprotion for 1: 0.921832884097035\n",
      "\n",
      "Quaterly proprotion for 0: 0.2944743935309973\n",
      "Quaterly proprotion for 1: 0.7055256064690026\n"
     ]
    }
   ],
   "source": [
    "print('Loan proportion for 0:', Loan_prop0)\n",
    "print('Loan proportion for 1:', Loan_prop1)\n",
    "\n",
    "print('\\nHalf_Yearly proprotion for 0:', HY_Freq0)\n",
    "print('Half_Yearly proprotion for 1:', HY_Freq1)\n",
    "\n",
    "print('\\nMonthly proprotion for 0:', Mon_Freq0)\n",
    "print('Monthly proprotion for 1:', Mon_Freq1)\n",
    "\n",
    "print('\\nQuaterly proprotion for 0:', Qua_Freq0)\n",
    "print('Quaterly proprotion for 1:', Qua_Freq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "f = 1\n",
    "\n",
    "lamda_HY = 1 / (1 + np.exp(-(HY_total - k)/f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamda_HY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
